{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUpuVXNGEuoCGV7X8dGk01"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ETL for extracting data from the files of B3 - historical data\n",
        "\n",
        "\n",
        "By SRS - 2S\n",
        "\n",
        "V.1\n",
        "\n",
        "Data extraction from the B3 by site and all files must be downloaded directly:\n",
        "\n",
        "\n",
        "https://www.b3.com.br/pt_br/market-data-e-indices/servicos-de-dados/market-data/historico/mercado-a-vista/series-historicas/\n",
        "\n",
        "\n",
        "Objective:  Extract information from the downloaded from B3 on historical quotes"
      ],
      "metadata": {
        "id": "36AZJAjJqGfm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing libraries\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "y_6E-fBPqGwW"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setting up the B3 file directory\n",
        "colab_folder = 'B3/'\n",
        "\n",
        "if colab_folder: # Authorise Colab com by copying the token generated from the link\n",
        "\n",
        "    from google.colab import drive # Important method for working with Google Drive folders\n",
        "    drive.mount('/content/gdrive') # Mount and make available the file system in Colab (linux)\n",
        "\n",
        "    # Navigate to your files folder\n",
        "    %cd gdrive/MyDrive/{colab_folder}\n",
        "    ! ls #  Linux command to list the contents\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89dMkD1Qtdj3",
        "outputId": "a2f890cb-fa79-4570-99d0-da6f15ccc5d1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "[Errno 2] No such file or directory: 'gdrive/MyDrive/B3/'\n",
            "/content/gdrive/MyDrive/B3\n",
            "COTAHIST_A1986.TXT  COTAHIST_A1994.TXT\tCOTAHIST_A2002.TXT  COTAHIST_A2010.TXT\tCOTAHIST_A2018.TXT\n",
            "COTAHIST_A1987.TXT  COTAHIST_A1995.TXT\tCOTAHIST_A2003.TXT  COTAHIST_A2011.TXT\tCOTAHIST_A2019.TXT\n",
            "COTAHIST_A1988.TXT  COTAHIST_A1996.TXT\tCOTAHIST_A2004.TXT  COTAHIST_A2012.TXT\tCOTAHIST_A2020.TXT\n",
            "COTAHIST_A1989.TXT  COTAHIST_A1997.TXT\tCOTAHIST_A2005.TXT  COTAHIST_A2013.TXT\tCOTAHIST_A2021.TXT\n",
            "COTAHIST_A1990.TXT  COTAHIST_A1998.TXT\tCOTAHIST_A2006.TXT  COTAHIST_A2014.TXT\tCOTAHIST_A2022.TXT\n",
            "COTAHIST_A1991.TXT  COTAHIST_A1999.TXT\tCOTAHIST_A2007.TXT  COTAHIST_A2015.TXT\tCOTAHIST_A2023.TXT\n",
            "COTAHIST_A1992.TXT  COTAHIST_A2000.TXT\tCOTAHIST_A2008.TXT  COTAHIST_A2016.TXT\tCOTAHIST_A2024.TXT\n",
            "COTAHIST_A1993.TXT  COTAHIST_A2001.TXT\tCOTAHIST_A2009.TXT  COTAHIST_A2017.TXT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for extracting data from files downloaded from the B3 website (historical data)\n",
        "def read_file(path, name_file, year_date, type_file):\n",
        "\n",
        "  _file = f'{path}{name_file}{year_date}.{type_file}'\n",
        "\n",
        "  # Define column widths\n",
        "  colspecs = [(2, 10),  (11, 12), (13, 24), (28, 39),\n",
        "            (57, 69), (70, 82), (83, 95), (109, 121),\n",
        "            (153, 170), (171, 188)]\n",
        "\n",
        "  # Column names\n",
        "  names = ['trading_date', 'codbdi', 'action', 'name_action', 'open_price',\n",
        "         'maximum_price', 'minimum_price', 'closing_price', 'trading_quantity',\n",
        "         'trade_volume']\n",
        "\n",
        "  # Path of the positional TXT file\n",
        "  #path_files = r'C:\\downloads\\B3\\COTAHIST_A2023.txt'\n",
        "\n",
        "  # Reading the positional TXT file\n",
        "  df = pd.read_fwf(_file, colspecs=colspecs, skiprows=1, skipfooter=1, names=names)\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "F8y7FnYclhKB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecting only the type of share = Standard Lot (2)\n",
        "def filter_stocks(df):\n",
        "  df = df[df['codbdi'] == 2]\n",
        "  df = df.drop(['codbdi'], axis = 1)\n",
        "  df.head()\n",
        "\n",
        "  return df\n"
      ],
      "metadata": {
        "id": "-V26tbRFmaTv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Date field conversion\n",
        "def parse_date(df):\n",
        "\n",
        "  df['dtrading_date'] = pd.to_datetime(df['trading_date'], format='%Y%m%d')\n",
        "\n",
        "  return(df)\n"
      ],
      "metadata": {
        "id": "42PBAA6nmoxJ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# version of numeric fields\n",
        "def parse_values(df):\n",
        "\n",
        "  df['open_price']    = (df['open_price']    / 100 ).astype(float)\n",
        "  df['maximum_price'] = (df['maximum_price'] / 100 ).astype(float)\n",
        "  df['minimum_price'] = (df['minimum_price'] / 100 ).astype(float)\n",
        "  df['closing_price'] = (df['closing_price'] / 100 ).astype(float)\n",
        "\n",
        "  return(df)\n"
      ],
      "metadata": {
        "id": "8Pl4cZYlmoz1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Combining the files\n",
        "\n",
        "def concat_files(path, name_file, year_date, type_file, final_file):\n",
        "\n",
        "  for i, y in enumerate(year_date):\n",
        "    df = read_file(path, name_file, y, type_file)\n",
        "    df = filter_stocks(df)\n",
        "    df = parse_date(df)\n",
        "    df = parse_values(df)\n",
        "\n",
        "    if i == 0:\n",
        "      df_final = df\n",
        "    else:\n",
        "      df_final = pd.concat([df_final, df])\n",
        "\n",
        "\n",
        "  df_final.to_csv(f'{path}//{final_file}', index=False)"
      ],
      "metadata": {
        "id": "8B6lqlIVmo2J"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Performing primary data extraction and conversion - last 5 years\n",
        "year_date = [ '2020', '2021', '2022', '2023', '2024']\n",
        "\n",
        "path = f'/content/gdrive/MyDrive/B3/'\n",
        "name_file = 'COTAHIST_A'\n",
        "type_file = 'TXT'\n",
        "final_file = 'B3_2020_a_2024.csv'\n",
        "\n",
        "concat_files( path, name_file, year_date, type_file, final_file)\n",
        "\n"
      ],
      "metadata": {
        "id": "nD0_4qFqrYTC"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}